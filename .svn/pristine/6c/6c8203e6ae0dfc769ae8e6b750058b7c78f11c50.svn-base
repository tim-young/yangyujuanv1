package com.yangyujuan.lucene;

import java.io.File;
import java.io.IOException;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.List;

import org.apache.lucene.analysis.Analyzer; 
import org.apache.lucene.analysis.standard.StandardAnalyzer; 
import org.apache.lucene.document.Document; 
import org.apache.lucene.document.Field;
import org.apache.lucene.document.FieldType;
import org.apache.lucene.document.IntField;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.DocsEnum;
import org.apache.lucene.index.Fields;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.Terms;
import org.apache.lucene.index.TermsEnum;
import org.apache.lucene.queryparser.classic.ParseException;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.DocIdSetIterator;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.TopScoreDocCollector;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.BytesRef;
import org.apache.lucene.util.Version;
import org.jsoup.Jsoup;

import com.yangyujuan.jdbc.dao.DaoFactory;
import com.yangyujuan.jdbc.dao.NewsDao;
import com.yangyujuan.jdbc.dao.NewsFilter;
import com.yangyujuan.jdbc.domain.News;
import com.yangyujuan.util.PropertiesUtil;



public class LuceneService {

	public void createIndex() throws IOException {
		 IndexWriter writer = null;  
	        try {  
	        	String indexPath = PropertiesUtil.get("indexPath");
	            // Directory directory = new RAMDirectory();  
	            Directory directory = FSDirectory.open(Paths.get(indexPath));  
	            Analyzer analyzer = new StandardAnalyzer();  
	            IndexWriterConfig iwc = new IndexWriterConfig(analyzer);  
	            writer = new IndexWriter(directory, iwc);  
	            Document document = null;  
	            
	            NewsDao newsDao = DaoFactory.getInstance().getUserDao();
	    		ArrayList<News> list = newsDao.getAllNewsList();
	    		
	    		int i = 0;
	    		for(News news : list){
	    			if(!NewsFilter.isRightIndex(news)){
	    				continue;
	    			}
	    			System.out.println("title:" + news.getTitle());  
	                document = new Document();  
	                document.add(new IntField("id", news.getId(), Field.Store.YES));
	                document.add(new StringField("title", news.getTitle(), Field.Store.YES));
	                document.add(new StringField("source", news.getSource(), Field.Store.YES));  
	                document.add(new StringField("path", news.getPubTime(), Field.Store.YES));
	                //由于正文是带html标签的字符串，所有用Jsoup去掉标签
	                document.add(new TextField("bodytext", Jsoup.parse(news.getBodytext()).text(), Field.Store.YES));
//	                document.add(new TextField("bodytexthtml", news.getBodytext(), Field.Store.NO));
	                
	                
	                writer.addDocument(document);  
	    		}
	        } catch (IOException e) {  
	            // TODO Auto-generated catch block  
	            e.printStackTrace();  
	        } finally {  
	            if (writer != null) {  
	                try {  
	                    writer.close();  
	                } catch (IOException e) {  
	                    // TODO Auto-generated catch block  
	                    e.printStackTrace();  
	                }  
	            }  
	        } 
	}

	public ArrayList<News> search(String keyword) throws ParseException{
	    ArrayList<News> ls = new ArrayList<News>();
	    
	    String indexPath = PropertiesUtil.get("indexPath");
        // Directory directory = new RAMDirectory();  
         
		try {
			Directory directory = FSDirectory.open(Paths.get(indexPath));
			Analyzer analyzer = new StandardAnalyzer();  
			DirectoryReader ireader = DirectoryReader.open(directory);
			IndexSearcher isearcher = new IndexSearcher(ireader);
			QueryParser parser = new QueryParser("bodytext", analyzer);
			Query query = parser.parse(keyword);
			ScoreDoc[] hits = isearcher.search(query, 10).scoreDocs;
			System.out.println(hits.length);
			for (int i = 0; i < hits.length; i++) {
				Document hitDoc = isearcher.doc(hits[i].doc);
				ls.add(document2News(hitDoc));
			}
			ireader.close();
			directory.close();
		} catch (IOException e) {
			e.printStackTrace();
		}  
		return ls;
	}
	
	public News document2News(Document document){
		News  model = new News();
		model.setId(Integer.parseInt(document.get("id")));
		model.setTitle(document.get("title"));
		model.setSource(document.get("source"));
		model.setPubTime(document.get("pubTime"));
		model.setBodytext(document.get("bodytext"));
		return model;
	}
	
	public void addIndex(News news){
		
	}
	
	public void getIndexMate(){
		 try {
			 	String indexPath = PropertiesUtil.get("indexPath");
	            // Directory directory = new RAMDirectory();  
	            Directory directory = FSDirectory.open(Paths.get(indexPath));  
//	            Directory directroy = FSDirectory.open(new File(
//	                    INDEX_PATH));
	            IndexReader reader = DirectoryReader.open(directory);
	            for (int i = 0; i < reader.numDocs(); i++) {
	                int docId = i;
	                System.out.println("第" + (i + 1) + "篇文档：");
	                Terms terms = reader.getTermVector(docId, "bodytext");
	                if (terms == null){
	                    continue;
	                }else{
	                	System.out.println(terms.toString());
	                }
	                TermsEnum termsEnum = terms.iterator();
	                BytesRef thisTerm = null;
	                while ((thisTerm = termsEnum.next()) != null) {
	                    String termText = thisTerm.utf8ToString();
	                    DocsEnum docsEnum = termsEnum.docs(null, null);
	                    while ((docsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
	                        System.out.println("termText:" + termText + " TF:  "
	                                + 1.0 * docsEnum.freq() / terms.size());
	                    }
	                }
	            }
	            reader.close();
	            directory.close();
	        } catch (Exception e) {
	            e.printStackTrace();
	        }
	}
	
}
